{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9236a923-32d9-4a77-a562-153a928a7088",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "In this example, I develop and train a deep learning model utilizing the Fashion-MNIST dataset, which comprises 28x28 grayscale images of various clothing items, such as shirts, sneakers, and coats, categorized into 10 distinct classes. The model, a fully connected neural network, is designed to accurately classify these images based on their visual features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7a588f-8aed-4d3b-ad43-d8b1acf524ca",
   "metadata": {},
   "source": [
    "## Step 1: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2976b681-033f-45ab-aca1-37a3feeb8f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8367e19-9f28-4338-b8af-1d741d2344af",
   "metadata": {},
   "source": [
    "## Step 2: Load and Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2109f94b-7793-440a-b34f-08697231151d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform: Convert images to tensors & normalize pixel values\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # mean = 0.5, std = 0.5 for grayscale\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20221880-f5af-40a1-8f05-5f425142ce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 9000362.95it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 215518.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 3992430.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 33218887.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download and load FashionMNIST dataset\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fba4a6b4-1a9d-41dc-b518-8e368d4b03ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into batches for efficient training and better learning\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7da1f2-04f9-4be9-babb-2cd1dc4ded70",
   "metadata": {},
   "source": [
    "## Step 3: Visualize Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82eb6f6c-fca5-4ec0-9f80-14242f3cf67c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "plt.imshow(images[0].squeeze(), cmap='gray')\n",
    "print(\"Label:\", labels[0].item())  # Label is a number from 0–9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f57822-64f4-4226-ad6f-feffd4670772",
   "metadata": {},
   "source": [
    "### Fashion-MNIST label names\n",
    "| Label | Class Name   |\n",
    "|-------|--------------|\n",
    "| 0     | T-shirt/top  |\n",
    "| 1     | Trouser      |\n",
    "| 2     | Pullover     |\n",
    "| 3     | Dress        |\n",
    "| 4     | Coat         |\n",
    "| 5     | Sandal       |\n",
    "| 6     | Shirt        |\n",
    "| 7     | Sneaker      |\n",
    "| 8     | Bag          |\n",
    "| 9     | Ankle boot   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b674f333-c78e-4f37-8702-fd303af52a66",
   "metadata": {},
   "source": [
    "## Step 4: Define a Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cae26a29-423d-485d-a17b-fcbff2172370",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)  # First hidden layer\n",
    "        self.fc2 = nn.Linear(128, 64)     # Second hidden layer\n",
    "        self.fc3 = nn.Linear(64, 10)      # Output: 10 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)         # Flatten the image (28x28 → 784)\n",
    "        x = torch.relu(self.fc1(x))   # Activation after first layer\n",
    "        x = torch.relu(self.fc2(x))   # Activation after second layer\n",
    "        x = self.fc3(x)               # Output layer (no softmax needed with CrossEntropy)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86849b91-0956-45f8-82bf-64d7523d56b8",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23d3b202-c3b6-4391-9024-cf325851bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001) # Use Adam and set learning rate as 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "485aa292-770a-49a5-9ef4-f20a6147d6c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4998\n",
      "Epoch 2, Loss: 0.3773\n",
      "Epoch 3, Loss: 0.3389\n",
      "Epoch 4, Loss: 0.3156\n",
      "Epoch 5, Loss: 0.2968\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        optimizer.zero_grad()           # Reset gradients\n",
    "        outputs = model(images)         # Forward pass\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()                 # Backward pass\n",
    "        optimizer.step()                # Update weights\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}, Loss: {running_loss/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55541cd8-d66c-4ae5-bb34-226e6676f791",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "359bf02a-0b20-44a1-a4d2-20ea40886fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set: 87.72%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "model.eval()  # Turn off dropout/batchnorm (if used)\n",
    "\n",
    "with torch.no_grad():  # No need to calculate gradients now\n",
    "    for images, labels in test_loader:\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)  # Get predicted class\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f\"Accuracy on test set: {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be833116-3ef9-45f5-9d28-2f353209479b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ca522-301e-46c3-b8e7-ed6b1e47dca4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.10]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
